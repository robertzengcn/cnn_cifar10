{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b28a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2c16c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85163135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,stride=1):\n",
    "        super(ResBlock,self).__init__()\n",
    "        self.layer=nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),                   \n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.shortcut=nn.Sequential()\n",
    "        if in_channels!=out_channels or stride>1:\n",
    "            #如果输入输出通道数不一致或者步长不为1，则需要添加shortcut\n",
    "            #shortcut的作用是将输入直接加到输出上\n",
    "            #如果输入输出通道数不一致，则需要通过卷积调整通道数\n",
    "            #如果步长不为1，则需要通过卷积调整步长\n",
    "            #这里的卷积核大小为3，步长为stride，padding为1\n",
    "            #这样可以保证输出的大小与输入的大小一致\n",
    "            #如果步长为1，则padding为1\n",
    "            #如果步长不为2，则padding为0\n",
    "            #如果步长不为3，则padding为1\n",
    "            #如果步长不为4，则padding为2\n",
    "            self.shortcut=nn.Sequential(\n",
    "                nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out1=self.layer(x)\n",
    "        out2=self.shortcut(x)\n",
    "        out=out1+out2\n",
    "        out=F.relu(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4af97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def make_layer(self,block,out_channel,stride,num_block):\n",
    "        layers_list=[]\n",
    "        for i in range(num_block):\n",
    "           if i==0:\n",
    "               in_stride=stride\n",
    "           else:\n",
    "               in_stride=1     \n",
    "           layers_list.append(block(self.in_channel,out_channel,in_stride)) \n",
    "           self.in_channel=out_channel \n",
    "        return nn.Sequential(*layers_list)\n",
    "    def __init__(self,ResBlock):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.in_channel=32\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(3,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # self.layer1=ResBlock(in_channel=32,\n",
    "        #                      out_channels=64,\n",
    "        #                      stride=2)\n",
    "        # self.layer2=ResBlock(in_channel=64,\n",
    "        #                      out_channels=64,\n",
    "        #                      stride=2)\n",
    "        # self.layer3=ResBlock(in_channel=64,\n",
    "        #                      out_channels=128,\n",
    "        #                      stride=2)\n",
    "        # self.layer4=ResBlock(in_channel=64,\n",
    "        #                      out_channels=128,\n",
    "        #                      stride=2)\n",
    "        self.layer1=self.make_layer(ResBlock,64,2,2)\n",
    "        self.layer2=self.make_layer(ResBlock,128,2,2)\n",
    "        self.layer3=self.make_layer(ResBlock,256,2,2)\n",
    "        self.layer4=self.make_layer(ResBlock,512,2,2)\n",
    "        self.fc=nn.Linear(512,10)  # 假设输出10个类别\n",
    "    def forward(self,x):\n",
    "        out=self.conv1(x)\n",
    "        out=self.layer1(out)\n",
    "        out=self.layer2(out)\n",
    "        out=self.layer3(out)\n",
    "        out=self.layer4(out)\n",
    "        out=F.avg_pool2d(out,2)  # 全局\n",
    "        out=out.view(out.size(0),-1)  # 展平\n",
    "        out=self.fc(out)  # 全连接层\n",
    "        return out\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf2a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet():\n",
    "    return ResNet(ResBlock)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-cifar10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
